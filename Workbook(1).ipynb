{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 LRU CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n",
    "#Using Hash map and Doubly Linked List\n",
    "#LRU CACHE\n",
    "class Node:\n",
    "    #creating DLL\n",
    "    def __init__(self,key,value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        \n",
    "            \n",
    "class LRU_Cache(object):\n",
    "    \n",
    "    #defining DLL nodes\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity  #max capacity to hold\n",
    "        self.hash_map = {}     #creating hash map\n",
    "        self.head = Node(0,0)         #creating dummy head node(0,0)\n",
    "        self.tail = Node(0,0)          #creating dummy tail node(0,0)\n",
    "        #linking head and tail to each other\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "        #None definition\n",
    "        self.head.prev = None\n",
    "        self.tail.next = None\n",
    "        \n",
    "    def add(self,key,value):\n",
    "        #created new_node\n",
    "        new_node = Node(key,value)\n",
    "        #set curr to tail\n",
    "        curr = self.head.next\n",
    "        #linking new_node to tail part or curr pointer \n",
    "        new_node.next = curr\n",
    "        curr.prev = new_node\n",
    "        #linking new_node to head part\n",
    "        self.head.next = new_node\n",
    "        new_node.prev= self.head\n",
    "        # added new_node to hashmap\n",
    "        self.hash_map[key] = new_node\n",
    "        \n",
    "    def delete(self,node):\n",
    "        #take 2 pointer nxt and prev to node\n",
    "        nxt = node.next\n",
    "        prev = node.prev\n",
    "        #assign and deleted node\n",
    "        nxt.prev = prev\n",
    "        prev.next = nxt\n",
    "        node.next = None\n",
    "        node.prev = None\n",
    "        node = None\n",
    "    \n",
    "    def get(self,key):\n",
    "        #if key in dictionary\n",
    "        if key in self.hash_map:\n",
    "            #delete node and get\n",
    "            self.delete(self.hash_map[key])\n",
    "            #and add to the most recent\n",
    "            self.add(key,self.hash_map[key].value)\n",
    "            return self.hash_map[key].value\n",
    "        return -1\n",
    "        \n",
    "    def set(self,key,value):\n",
    "        #if key already in dictionary\n",
    "        if key in self.hash_map:\n",
    "            self.delete(self.hash_map[key]) #delete the node at that key\n",
    "            del self.hash_map[key] #delete the value at that key\n",
    "            self.add(key,value)    #add node to that key\n",
    "        #else if len of hash_map == capacity\n",
    "        elif len(self.hash_map)== self.capacity:\n",
    "            #delete LRU node from dict\n",
    "            del self.hash_map[self.tail.prev.key]\n",
    "            #delete LRU node\n",
    "            self.delete(self.tail.prev)\n",
    "            #add new_node\n",
    "            self.add(key,value)\n",
    "        else:\n",
    "            #add node to DLL and add to hash_map if key not in dict\n",
    "            #add 1,2,3,4 limit 5\n",
    "            self.add(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.set(1, 1);\n",
    "our_cache.set(2, 2);\n",
    "our_cache.set(3, 3);\n",
    "our_cache.set(4, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cache.get(1)       # returns 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cache.get(2)       # returns 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cache.get(9)      # returns -1 because 9 is not present in the cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cache.set(5, 5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cache.set(6, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cache.get(3) # returns -1 because the cache reached it's capacity and 3 was the least recently used entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Complexity\n",
    "#### The hash map makes the time of get() to be O(1). The list of double linked nodes make the nodes adding/removal operations O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Finding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.Note that a path may \n",
    "    contain further subdirectories and those subdirectories may also contain\n",
    "    further subdirectories.There are no limit to the depth of the subdirectories\n",
    "    can be.\n",
    "    Args:\n",
    "        suffix(str): suffix if the file name to be found\n",
    "        path(str): path of the file system\n",
    "    Returns:\n",
    "        list: a list of paths\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    if os.path.isdir(path):\n",
    "        # iterating items\n",
    "        for item in os.listdir(path):\n",
    "            # Recursion and appending to list\n",
    "            for file in find_files(suffix, os.path.join(path, item)):\n",
    "                files.append(file)\n",
    "    # suffix end with .c, add it to the list\n",
    "    if path.endswith(suffix):\n",
    "        files.append(path)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Workbook.ipynb', '.ipynb_checkpoints']\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let us print the files in the directory in which you are running this script\n",
    "print (os.listdir(\".\"))\n",
    "\n",
    "# Let us check if this file is indeed a file!\n",
    "print (os.path.isfile(\"./ex.py\"))  #return False\n",
    "\n",
    "# Does the file end with .py?\n",
    "print (\"./ex.py\".endswith(\".py\")) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_files(\".c\",\"./testdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail\n",
      "Pass\n",
      "Pass\n",
      "Pass\n",
      "Pass\n"
     ]
    }
   ],
   "source": [
    "print(\"Pass\" if find_files(\".c\",\"./testdir\") == [\"./testdir/subdir3/subsubdir1/b.c\", \"./testdir/t1.c\",\n",
    "                                                  \"./testdir/subdir5/a.c\", \"./testdir/subdir1/a.c\"] else \"Fail\")\n",
    "print(\"Pass\" if find_files(\".c\",\"./testdir/t1.c\") == [\"./testdir/t1.c\"] else \"Fail\")\n",
    "print(\"Pass\" if find_files(\".c\",\"./testdir/subdir3/subsubdir1/b.c\") == [\"./testdir/subdir3/subsubdir1/b.c\"] else \"Fail\") \n",
    "print(\"Pass\" if find_files(\".c\",\"\") == [] else \"Fail\") #edge case when path is not provided\n",
    "print(\"Pass\" if find_files(\".c\",\"./testdir/subdir2\") == [] else \"Fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./testdir/t1.c']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_files(\".c\",\"./testdir/t1.c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used recurision  and concatenated new valid file to current path, then return the new files found and extended<br>current list of files with them\n",
    "\n",
    "## Time Complexity\n",
    "#### O(mn) because loop over all files includes number of sub directories, m and number of files per directory, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 Huffman Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data is: 69\n",
      "\n",
      "The content of the data is: The bird is the word\n",
      "\n",
      "The size of the encoded data is: 48\n",
      "\n",
      "The content of the encoded data is: 100000010000000100000000000101000000001000000000100000000001000000000001000000001001000000000001000100000010000000100000000000100001000001000000000100000000001\n",
      "\n",
      "The size of the decoded data is: 69\n",
      "\n",
      "The content of the encoded data is: The bird is the word\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def huffman_encoding(data):\n",
    "    table = dict()\n",
    "    for char in data:\n",
    "        table[char] = table.get(char, 0) + 1\n",
    "    tree = dict()\n",
    "    temp = '1'\n",
    "    for i in sorted(table.items(), key = lambda x: x[1]):\n",
    "        tree[i[0]] = temp\n",
    "        temp = '0' + temp\n",
    "\n",
    "    encoded = ''\n",
    "    for i in data:\n",
    "        encoded += tree[i]\n",
    "    return encoded, tree\n",
    "\n",
    "def huffman_decoding(data,tree):\n",
    "    huff = dict()\n",
    "    for char in tree:\n",
    "        huff[tree[char]] = char\n",
    "    store = ''\n",
    "    decoded = ''\n",
    "    for d in data:\n",
    "        if d == '1':\n",
    "            decoded += huff[store + d]\n",
    "            store = ''\n",
    "        else:\n",
    "            store += d\n",
    "    return decoded\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    codes = {}\n",
    "\n",
    "    a_great_sentence = \"The bird is the word\"\n",
    "\n",
    "    print (\"The size of the data is: {}\\n\".format(sys.getsizeof(a_great_sentence)))\n",
    "    print (\"The content of the data is: {}\\n\".format(a_great_sentence))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(a_great_sentence)\n",
    "\n",
    "    print (\"The size of the encoded data is: {}\\n\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print (\"The size of the decoded data is: {}\\n\".format(sys.getsizeof(decoded_data)))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(decoded_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Time Complexity\n",
    "#### The time complexity for encoding each unique character based on its frequency is O(nlog n).<br>Extracting minimum frequency from the priority queue takes place 2*(n-1) times and its complexity is O(log n). Thus the overall complexity is O(nlog n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 Active Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_user_in_group(user, group):\n",
    "    \"\"\"\n",
    "    Return True if user is in the group, False otherwise.\n",
    "\n",
    "    Args:\n",
    "      user(str): user name/id\n",
    "      group(class:Group): group to check user membership against\n",
    "    \"\"\"\n",
    "    if user in group.get_users():\n",
    "        return True\n",
    "    for i in group.get_groups():\n",
    "        if is_user_in_group(user, i):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n",
    "\n",
    "\n",
    "print(is_user_in_group(\"child\", child))  \n",
    "# Should return True\n",
    "print(is_user_in_group(\"\", child))  \n",
    "# Should return False\n",
    "print(is_user_in_group(\"sub_child_user\", parent))  \n",
    "# Should return True\n",
    "print(is_user_in_group(sub_child_user, sub_child))  \n",
    "# Should return True\n",
    "print(is_user_in_group(sub_child_user, child))  \n",
    "# Should return True\n",
    "print(is_user_in_group(sub_child_user, parent))  \n",
    "# Should return \"True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 BlockChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "class Block:\n",
    "    def __init__(self,data, previous_hash):\n",
    "        self.timestamp = time.strftime(\"%a, %d %b %Y %I:%M:%S %p %Z\", time.gmtime())\n",
    "        self.data = data\n",
    "        self.previous_hash = previous_hash\n",
    "        self.hash = self.calc_hash(self.data)\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "\n",
    "    def calc_hash(self, hash_str):\n",
    "        sha = hashlib.sha256()\n",
    "        hash_str = \"We are going to encode this string of data!\".encode('utf-8')\n",
    "        sha.update(hash_str)\n",
    "        return sha.hexdigest()\n",
    "        \n",
    "    \n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        \n",
    "    def append(self,data):\n",
    "        if self.head is None:\n",
    "            self.head = Block(data, 0)\n",
    "            self.tail = self.head\n",
    "            return\n",
    "\n",
    "        self.tail.next = Block(data, self.tail.hash)\n",
    "        self.tail.next.previous = self.tail\n",
    "        self.tail = self.tail.next\n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        cur_head = self.head\n",
    "        out_string = \"\"\n",
    "        while cur_head:\n",
    "            out_string += '|'+cur_head.timestamp + ',' + str(cur_head.data) + ',' +cur_head.hash +',' + str(cur_head.previous_hash) + '|'+  \" <- \"\n",
    "            cur_head = cur_head.next\n",
    "        return out_string\n",
    "    \n",
    "    def size(self):\n",
    "        size = 0\n",
    "        node = self.head\n",
    "        while node:\n",
    "            size += 1\n",
    "            node = node.next\n",
    "        \n",
    "        return size\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Wed, 07 Jul 2021 09:08:12 PM GMT,my first blockchain,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10,0| <- |Wed, 07 Jul 2021 09:08:12 PM GMT,second blockchain,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10| <- |Wed, 07 Jul 2021 09:08:12 PM GMT,third blockchain,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10| <- |Wed, 07 Jul 2021 09:08:12 PM GMT,forth blockchain,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10,a20200a94c75010576e2d6a83e6fa69271901a9d805894b28bd91e6054fbfd10| <- \n",
      "Data is a required input to the block\n"
     ]
    }
   ],
   "source": [
    "b1 = LinkedList() \n",
    "b1.append('my first blockchain')\n",
    "b1.append('second blockchain')\n",
    "b1.append('third blockchain')\n",
    "b1.append('forth blockchain')\n",
    "print(b1)\n",
    "\n",
    "# Test 2: empty blocks\n",
    "b2 = LinkedList()\n",
    "try:\n",
    "    b2.append() #raise error when trying to create a block with no data\n",
    "except TypeError:\n",
    "    print(\"Data is a required input to the block\")\n",
    "\n",
    "# Test 3: intput data has to be integer type\n",
    "b3 = LinkedList()\n",
    "b3.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Doubly Linked list to create block chain, used to store previous hash table in next table with other new transaction.\n",
    "## Time Complexity\n",
    "#### Time complexity of searching and traversing the linked list is O (n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 Union and Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1\n",
      "\n",
      "Union\t\t 32 -> 65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 9 -> 11 -> 21 -> \n",
      "Intersection\t 4 -> 21 -> 6 -> \n",
      "\n",
      "Test case 2\n",
      "\n",
      "Union\t\t 65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 7 -> 8 -> 9 -> 11 -> 21 -> 23 -> \n",
      "Intersection\t\t None\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def __str__(self):\n",
    "        cur_head = self.head\n",
    "        out_string = \"\"\n",
    "        while cur_head:\n",
    "            out_string += str(cur_head.value) + \" -> \"\n",
    "            cur_head = cur_head.next\n",
    "        return out_string\n",
    "\n",
    "\n",
    "    def append(self, value):\n",
    "\n",
    "        if self.head is None:\n",
    "            self.head = Node(value)\n",
    "            return\n",
    "\n",
    "        node = self.head\n",
    "        while node.next:\n",
    "            node = node.next\n",
    "\n",
    "        node.next = Node(value)\n",
    "\n",
    "    def size(self):\n",
    "        size = 0\n",
    "        node = self.head\n",
    "        while node:\n",
    "            size += 1\n",
    "            node = node.next\n",
    "        return size\n",
    "\n",
    "def union(llist_1, llist_2):\n",
    "    # Your Solution Here\n",
    "    #final result list\n",
    "    res = LinkedList()\n",
    "    \n",
    "    if llist_1.head is None and llist_2 is None:\n",
    "        return None\n",
    "    \n",
    "    #stored in set1()\n",
    "    set1 = set()\n",
    "    head1 = llist_1.head\n",
    "    while head1:\n",
    "        set1.add(head1.value)\n",
    "        head1 = head1.next\n",
    "\n",
    "    #stored in set2()\n",
    "    set2 = set()\n",
    "    head2 = llist_2.head\n",
    "    while head2:\n",
    "        set2.add(head2.value)\n",
    "        head2 = head2.next\n",
    "    \n",
    "    head_f = Node(None)\n",
    "    #MERGE unique item to set1\n",
    "    set1.update(set2)\n",
    "    \n",
    "\n",
    "    #convert set to list\n",
    "    updated_list = list(set1)\n",
    "    \n",
    "    #convert list to Linked_list\n",
    "    for i in range(len(updated_list)):\n",
    "        res.append(updated_list[i])\n",
    "    return res\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def intersection(llist_1, llist_2):\n",
    "    res = LinkedList()\n",
    "    \n",
    "    #Check if list1 and list2 is empty \n",
    "    if llist_1.head is None and llist_2 is None:\n",
    "        return None\n",
    "    #create hash_map for incoming data\n",
    "    set_1 = set()\n",
    "    temp_1 = llist_1.head\n",
    "    while temp_1:\n",
    "        set_1.add(temp_1.value)\n",
    "        temp_1 = temp_1.next\n",
    "      \n",
    "    set_2 = set()\n",
    "    temp_2 = llist_2.head\n",
    "    while temp_2:\n",
    "        set_2.add(temp_2.value)\n",
    "        temp_2 = temp_2.next\n",
    "     \n",
    "        temp_list = set_1.intersection(set_2)\n",
    "        if len(temp_list)==0:\n",
    "            return None\n",
    "    for item in temp_list:\n",
    "        res.append(item)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Test case 1\n",
    "\n",
    "linked_list_1 = LinkedList()\n",
    "linked_list_2 = LinkedList()\n",
    "\n",
    "element_1 = [3,2,4,35,6,65,6,4,3,21]\n",
    "element_2 = [6,32,4,9,6,1,11,21,1]\n",
    "\n",
    "for i in element_1:\n",
    "    linked_list_1.append(i)\n",
    "\n",
    "for i in element_2:\n",
    "    linked_list_2.append(i)\n",
    "\n",
    "print(\"\\nTest case 1\\n\")\n",
    "print (\"Union\\t\\t\",union(linked_list_1,linked_list_2))\n",
    "print (\"Intersection\\t\",intersection(linked_list_1,linked_list_2))\n",
    "\n",
    "# Test case 2\n",
    "\n",
    "linked_list_3 = LinkedList()\n",
    "linked_list_4 = LinkedList()\n",
    "\n",
    "element_1 = [3,2,4,35,6,65,6,4,3,23]\n",
    "element_2 = [1,7,8,9,11,21,1]\n",
    "\n",
    "for i in element_1:\n",
    "    linked_list_3.append(i)\n",
    "\n",
    "for i in element_2:\n",
    "    linked_list_4.append(i)\n",
    "print(\"\\nTest case 2\\n\")\n",
    "print (\"Union\\t\\t\",union(linked_list_3,linked_list_4))\n",
    "print (\"Intersection\\t\\t\",intersection(linked_list_3,linked_list_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implemented set using hash tables and having worst case time complexity of O(n) for adding and geting values but for lookup it complexity is O(1)\n",
    "\n",
    "## Time Complexity\n",
    "#### Union = O(n)\n",
    "#### Intersection = O(n)\n",
    "\n",
    "## Space Complexity\n",
    "#### O(n) = size of input llist_1 and llist_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
